{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processor import DataProcessor\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DataProcessor(\"../data/Train.csv\", test = False, minimal = True)\n",
    "x_train, x_valid, y_train, y_valid = processor.get_numpy_data(True, True, True, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using:  Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "print(\"using: \", torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train).float().to(device)\n",
    "x_valid = torch.tensor(x_valid).float().to(device)\n",
    "y_train = torch.tensor(y_train).float().to(device)\n",
    "y_valid = torch.tensor(y_valid).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int (len(x_train)/10)\n",
    "n_epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor = nn.Linear(in_features = len(x_train[0]), out_features = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    model.to(device)\n",
    "    cirterion = nn.MSELoss()\n",
    "    learning_rate = .01\n",
    "    optimizer = Adam(model.parameters(), lr = learning_rate)\n",
    "    old_loss = 1 \n",
    "    for i in range (n_epochs): \n",
    "        for b in range(0, len(x_train), batch_size):\n",
    "            predictions = model(x_train[b:b+batch_size])\n",
    "            loss = cirterion(predictions, y_train[b:b+batch_size])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "        if i % 100 == 0: \n",
    "            print(\"The loss after 100 epoch is: \", loss.item())\n",
    "            if (loss.item() - old_loss) / loss  < 1e-4:\n",
    "                learning_rate /= 2\n",
    "                optimizer = Adam(model.parameters(), lr = learning_rate)\n",
    "                old_loss = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_regressor = nn.Sequential(\n",
    "nn.Linear(in_features = len(x_train[0]), out_features = 50),\n",
    "nn.ReLU(),\n",
    "nn.BatchNorm1d(50),    \n",
    "nn.Linear(in_features = 50, out_features = 20), \n",
    "nn.ReLU(),\n",
    "nn.BatchNorm1d(20),\n",
    "nn.Linear(in_features = 20, out_features = 20), \n",
    "nn.ReLU(),\n",
    "nn.BatchNorm1d(20),\n",
    "nn.Linear(in_features = 20, out_features = 10), \n",
    "nn.ReLU(),\n",
    "nn.BatchNorm1d(10),\n",
    "nn.Linear(in_features = 10, out_features = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural_regressor.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after 100 epoch is:  2311948.0\n",
      "The loss after 100 epoch is:  4320.00390625\n",
      "The loss after 100 epoch is:  5784.4306640625\n",
      "The loss after 100 epoch is:  8255.5390625\n",
      "The loss after 100 epoch is:  6859.3857421875\n",
      "The loss after 100 epoch is:  6913.16796875\n",
      "The loss after 100 epoch is:  6134.36669921875\n",
      "The loss after 100 epoch is:  6489.5009765625\n",
      "The loss after 100 epoch is:  7015.49755859375\n",
      "The loss after 100 epoch is:  5291.94921875\n",
      "The loss after 100 epoch is:  5921.638671875\n",
      "The loss after 100 epoch is:  8100.6396484375\n",
      "The loss after 100 epoch is:  5887.9580078125\n",
      "The loss after 100 epoch is:  5658.33056640625\n",
      "The loss after 100 epoch is:  5675.6337890625\n",
      "The loss after 100 epoch is:  5639.24560546875\n",
      "The loss after 100 epoch is:  14227.1787109375\n",
      "The loss after 100 epoch is:  6378.79345703125\n",
      "The loss after 100 epoch is:  5501.634765625\n",
      "The loss after 100 epoch is:  5778.5185546875\n",
      "The loss after 100 epoch is:  7211.68017578125\n",
      "The loss after 100 epoch is:  9734.9521484375\n",
      "The loss after 100 epoch is:  10004.353515625\n",
      "The loss after 100 epoch is:  5549.4111328125\n",
      "The loss after 100 epoch is:  6211.6337890625\n",
      "The loss after 100 epoch is:  5325.66455078125\n",
      "The loss after 100 epoch is:  7719.17138671875\n",
      "The loss after 100 epoch is:  5791.513671875\n",
      "The loss after 100 epoch is:  5624.75390625\n",
      "The loss after 100 epoch is:  5442.9912109375\n",
      "The loss after 100 epoch is:  5114.39794921875\n",
      "The loss after 100 epoch is:  5403.583984375\n",
      "The loss after 100 epoch is:  5210.82421875\n",
      "The loss after 100 epoch is:  5348.29052734375\n",
      "The loss after 100 epoch is:  5295.25146484375\n",
      "The loss after 100 epoch is:  5273.625\n",
      "The loss after 100 epoch is:  5489.3984375\n",
      "The loss after 100 epoch is:  5323.6640625\n",
      "The loss after 100 epoch is:  5650.2568359375\n",
      "The loss after 100 epoch is:  5670.72900390625\n",
      "The loss after 100 epoch is:  5474.80908203125\n",
      "The loss after 100 epoch is:  5312.52734375\n",
      "The loss after 100 epoch is:  5374.2412109375\n",
      "The loss after 100 epoch is:  5959.3291015625\n",
      "The loss after 100 epoch is:  6319.59375\n",
      "The loss after 100 epoch is:  5611.7138671875\n",
      "The loss after 100 epoch is:  7638.7998046875\n",
      "The loss after 100 epoch is:  5316.666015625\n",
      "The loss after 100 epoch is:  7136.845703125\n",
      "The loss after 100 epoch is:  6767.8154296875\n",
      "The loss after 100 epoch is:  6245.294921875\n",
      "The loss after 100 epoch is:  5475.9228515625\n",
      "The loss after 100 epoch is:  5655.990234375\n",
      "The loss after 100 epoch is:  5888.4013671875\n",
      "The loss after 100 epoch is:  5438.685546875\n",
      "The loss after 100 epoch is:  8876.7578125\n",
      "The loss after 100 epoch is:  6138.72314453125\n",
      "The loss after 100 epoch is:  5738.05419921875\n",
      "The loss after 100 epoch is:  6446.46533203125\n",
      "The loss after 100 epoch is:  5316.77392578125\n",
      "The loss after 100 epoch is:  5202.2783203125\n",
      "The loss after 100 epoch is:  6288.9248046875\n",
      "The loss after 100 epoch is:  5604.2841796875\n",
      "The loss after 100 epoch is:  5485.16357421875\n",
      "The loss after 100 epoch is:  7154.7265625\n",
      "The loss after 100 epoch is:  6378.0380859375\n",
      "The loss after 100 epoch is:  7750.86865234375\n",
      "The loss after 100 epoch is:  6451.3095703125\n",
      "The loss after 100 epoch is:  5294.23828125\n",
      "The loss after 100 epoch is:  7704.0849609375\n",
      "The loss after 100 epoch is:  36620.41796875\n",
      "The loss after 100 epoch is:  5733.22021484375\n",
      "The loss after 100 epoch is:  8132.390625\n",
      "The loss after 100 epoch is:  5676.04931640625\n",
      "The loss after 100 epoch is:  9082.2783203125\n",
      "The loss after 100 epoch is:  5857.04931640625\n",
      "The loss after 100 epoch is:  5618.984375\n",
      "The loss after 100 epoch is:  5645.70703125\n",
      "The loss after 100 epoch is:  10772.5869140625\n",
      "The loss after 100 epoch is:  7331.837890625\n",
      "The loss after 100 epoch is:  7041.40673828125\n",
      "The loss after 100 epoch is:  5532.759765625\n",
      "The loss after 100 epoch is:  5174.90966796875\n",
      "The loss after 100 epoch is:  5807.7607421875\n",
      "The loss after 100 epoch is:  5542.3603515625\n",
      "The loss after 100 epoch is:  5193.3369140625\n",
      "The loss after 100 epoch is:  5258.271484375\n",
      "The loss after 100 epoch is:  6356.54443359375\n",
      "The loss after 100 epoch is:  6118.07275390625\n",
      "The loss after 100 epoch is:  6194.783203125\n",
      "The loss after 100 epoch is:  7746.4697265625\n",
      "The loss after 100 epoch is:  5420.1416015625\n",
      "The loss after 100 epoch is:  6291.9580078125\n",
      "The loss after 100 epoch is:  5585.974609375\n",
      "The loss after 100 epoch is:  7633.55517578125\n",
      "The loss after 100 epoch is:  5612.37548828125\n",
      "The loss after 100 epoch is:  5523.2197265625\n",
      "The loss after 100 epoch is:  6954.81787109375\n",
      "The loss after 100 epoch is:  7615.19140625\n",
      "The loss after 100 epoch is:  6445.21533203125\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/trained_regressor_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a1cfa57d4833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneural_regressor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneural_regressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models/trained_regressor_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/trained_regressor_1'"
     ]
    }
   ],
   "source": [
    "train(neural_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(neural_regressor.state_dict(), \"models/trained_regressor_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi this is me\n"
     ]
    }
   ],
   "source": [
    "print(\"hi this is me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
