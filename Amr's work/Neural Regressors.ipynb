{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processor import DataProcessor\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1 = \"../data/Train.csv\"\n",
    "file_2 = \"../data/additional_data/trainRoot_edited.csv\"\n",
    "\n",
    "processor = DataProcessor(file_1, file_2, test = False, minimal = True)\n",
    "x_train, x_valid, y_train, y_valid = processor.get_numpy_data(fillna = True, additional = True,\n",
    "                                                                            encode = True, np_split = True, enocde_user = False,\n",
    "                                                                            normalize = True, drop_ones = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train).float().to(device)\n",
    "x_valid = torch.tensor(x_valid).float().to(device)\n",
    "y_train = torch.tensor(y_train).float().to(device)\n",
    "y_valid = torch.tensor(y_valid).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int (len(x_train)/25)\n",
    "n_epochs = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor = nn.Linear(in_features = len(x_train[0]), out_features = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    model.to(device)\n",
    "    cirterion = nn.MSELoss()\n",
    "    learning_rate = .02\n",
    "    optimizer = Adam(model.parameters(), lr = learning_rate)\n",
    "    old_loss = 590720.5\n",
    "    \n",
    "    for i in range (n_epochs): \n",
    "        for b in range(0, len(x_train), batch_size):\n",
    "            predictions = model(x_train[b:b+batch_size])\n",
    "            loss = cirterion(predictions, y_train[b:b+batch_size])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "        if i % 1000 == 0: \n",
    "            print(\"The loss after 1000 epoch is: \", loss.item())\n",
    "            \n",
    "        if i % 10000 == 0:\n",
    "            learning_rate /= 2\n",
    "            print(\"The learning rate now is: \", learning_rate)\n",
    "            old_loss = loss.item()\n",
    "            optimizer = Adam(model.parameters(), lr = learning_rate)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_regressor = nn.Sequential(\n",
    "nn.Linear(in_features = len(x_train[0]), out_features = 10),\n",
    "nn.ReLU(),\n",
    "nn.BatchNorm1d(10),    \n",
    "nn.Linear(in_features = 10, out_features = 10), \n",
    "nn.ReLU(),\n",
    "nn.BatchNorm1d(10),\n",
    "nn.Linear(in_features = 10, out_features = 10), \n",
    "nn.ReLU(),\n",
    "nn.BatchNorm1d(10),\n",
    "nn.Linear(in_features = 10, out_features = 10), \n",
    "nn.ReLU(),\n",
    "nn.BatchNorm1d(10),\n",
    "nn.Linear(in_features = 10, out_features = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=26, out_features=10, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (10): ReLU()\n",
       "  (11): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_regressor.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after 1000 epoch is:  3874074.5\n",
      "The learning rate now is:  0.01\n",
      "The loss after 1000 epoch is:  41056.34765625\n",
      "The loss after 1000 epoch is:  761656.875\n",
      "The loss after 1000 epoch is:  41267.54296875\n",
      "The loss after 1000 epoch is:  44321.1484375\n",
      "The loss after 1000 epoch is:  23560.890625\n",
      "The loss after 1000 epoch is:  27967.0625\n",
      "The loss after 1000 epoch is:  24679.720703125\n"
     ]
    }
   ],
   "source": [
    "train(neural_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(neural_regressor.state_dict(), \"models/working_trained_regressor_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = torch.load(\"models/trained_regressor_1\", map_location={'cuda:0': 'cpu'})\n",
    "#neural_regressor.state_dict = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = neural_regressor(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x, y): \n",
    "    predictions = model(x).detach().cpu().numpy().reshape(-1)\n",
    "    #predictions = torch.tensor([1500.]*len(y))\n",
    "    y = y.cpu().numpy().reshape(-1)\n",
    "    error = mean_squared_error(y, predictions)\n",
    "    var = np.var(y)\n",
    "    print(\"The MSE error is: \", error)\n",
    "    print(\"The variance of the validation set is: \", var)\n",
    "    r_2 = 1 - error / var \n",
    "\n",
    "    print(\"The model explians \" ,r_2 , \" of the variance in data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(neural_regressor, x_train, y_train)\n",
    "evaluate(neural_regressor, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor = DataProcessor(\"../data/Test.csv\", test = True)\n",
    "# x_test = processor.get_numpy_data(True, True, True, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
